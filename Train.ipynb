{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h5>START WITH IMPORTING LIBRARIES</h5></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Import for handling tabular data\n",
    "from sklearn.model_selection import train_test_split # Import for partitioning\n",
    "\n",
    "from sklearn.pipeline import make_pipeline # Import for making machine learning pipeline\n",
    "from sklearn.preprocessing import StandardScaler # Import for normalizing data\n",
    "\n",
    "# Classification algorithms\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score # Accuracy or performance metrics \n",
    "import pickle # Saves the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h5>SET UP FEATURES, TARGET VARIABLE, AND CREATE TRAIN TEST SPLIT (DATA PROCESSING)</h5></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read collected data \n",
    "df = pd.read_csv('coords.csv')\n",
    "\n",
    "# Data processing\n",
    "X = df.drop('class', axis=1) # features\n",
    "y = df['class'] # target value\n",
    "\n",
    "# Create training and testing partition\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h5>TRAINING MACHINE LEARNING CLASSIFICATION MODEL</h5></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating machine learning pipelines\n",
    "# Each pipeline is a sequence of steps that will be applied to the data\n",
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}\n",
    "\n",
    "# Training step\n",
    "# Looping through each pipeline\n",
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, y_train) # the training method and training data\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h5>EVALUATING THE MODEL</h5></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping and printing the accuracy score for each model \n",
    "for algo, model in fit_models.items():\n",
    "    yhat = model.predict(X_test)\n",
    "    print(algo, accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><h5>SAVING THE MODEL</h5></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a model to export\n",
    "with open('body_language.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['rf'], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
